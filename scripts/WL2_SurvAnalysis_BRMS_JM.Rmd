---
title: "WL2_Survival-Analysis"
author: "Julin Maloof"
date: '`r Sys.Date()`'
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Survival Analysis 

See chapters 9 - 13 in tutorial: https://bookdown.org/content/4253/extending-the-discrete-time-hazard-model.html

## Libraries
```{r}
# install.packages(c("ggsurvfit", "gtsummary"))
library(tidyverse) #includes lubridate, which we need 
library(ggrepel)
#library(ggsurvfit)
#library(gtsummary)
library(brms)
library(ggdist)
library(tidybayes)
library(modelr)
#library(bayesplot)
options(mc.cores = parallel::detectCores())
```

## Read in the data
```{r}
wl2_surv <- read_csv("../input/WL2_Data/CorrectedCSVs/WL2_mort_pheno_20231020_corrected.csv",
                     na = c("", "NA", "-", "N/A")) %>% #note this only goes to 10/20 need to come back and change this to include dates after this
  select(block:rep, death.date, survey.notes) %>% 
  rename(parent.pop=pop) %>% 
  mutate(parent.pop= str_replace(parent.pop, "Y08", "YO8")) %>% 
  mutate(parent.pop= str_replace(parent.pop, "Y04", "YO4")) %>% 
  filter(!is.na(parent.pop)) %>% 
  unite(BedLoc, bed:bed.col, sep="_", remove = FALSE) %>% 
  unite(Genotype, parent.pop:rep, sep="_", remove = FALSE) %>% 
  filter(!str_detect(Genotype, ".*buff*")) %>% 
  unite(pop.mf, parent.pop:mf, sep="_", remove = FALSE)
head(wl2_surv)
unique(wl2_surv$parent.pop)

wl2_surv %>% filter(Genotype=="CC_1_2") #there are 2 CC_1_2 plants (in different field locs), CC-1-2 was planted in 13-A and not 5C according to planting notes 
wl2_surv %>% filter(Genotype=="IH_4_5") #there are 2 IH_4_5 plants (in different field locs), IH_4_5 was planted in 22B and not 32A according to planting notes 
wl2_surv %>% rowwise() %>%  #checking if mf and rep can be converted to numeric 
  filter(!is.na(rep)) %>%  
  filter(is.na(as.numeric(rep)))
```

As weeks
```{r}
wl2_surv %>% filter(is.na(death.date),!is.na(survey.notes)) #no plants that seemed to disappear 
wl2_surv %>% filter(Genotype=="YO7_4_2")

wl2_surv_dates <- wl2_surv %>% 
  filter(BedLoc!="K_5_C") %>% 
  filter(BedLoc!="B_32_A") %>% 
  mutate(mf=as.double(mf), rep=as.double(rep)) %>% 
  mutate(planting.date="7/19/23", #could try to make this more specific to when certain blocks were planted 
         last_fup_date=if_else(is.na(death.date), "10/20/23", death.date)) %>%  #need this to calculate survival times
  mutate(planting.date=mdy(planting.date), last_fup_date=mdy(last_fup_date)) %>% #convert to date objects
  mutate(os_weeks=as.duration(planting.date %--% last_fup_date) / dweeks(1), #observed number of weeks
         status=if_else(is.na(death.date), 0, 1)) %>% #0=censured (alive in this case), 1=dead
  filter(os_weeks > 0) %>% #there is one case of a plant that was dead at planting, so just removed it since this is survival post- transplanting
  select(-survey.notes)
head(wl2_surv_dates)
unique(wl2_surv_dates$os_weeks)
```


```{r}
wl2_surv_dates %>% filter(parent.pop=="WL2") #there's a different number of WL2 plants here compared to annual census (see FirstYear Survv)
```

## Location Info
```{r}
gowersdist_UCD <- read_csv("../output/Climate/Pops_GowersEnvtalDist_UCD.csv") %>% 
  rename(Recent_Gowers_Dist_UCD = Recent_Gowers_Dist, Historic_Gowers_Dist_UCD = Historic_Gowers_Dist)
head(gowersdist_UCD)
gowersdist_WL2 <- read_csv("../output/Climate/Pops_GowersEnvtalDist_WL2.csv") %>% 
  rename(Recent_Gowers_Dist_WL2 = Recent_Gowers_Dist, Historic_Gowers_Dist_WL2 = Historic_Gowers_Dist)
head(gowersdist_WL2)

gowersdist_all <- full_join(gowersdist_UCD, gowersdist_WL2)
head(gowersdist_all)
```

```{r}
wl2_surv_dates_loc <- left_join(wl2_surv_dates, gowersdist_all) %>%
  mutate(elevation.group = factor(elevation.group, levels= c("Low", "Mid", "High")))
wl2_surv_dates_loc
```
## plot observed data

Need to summarize separately for pops and for elevation.  It is a mistake to average pops and then elevation, at least with respect to comparing to population naive models

### population-level summary
```{r}
# set up week 0 for 100% survival
week0.pop <- wl2_surv_dates_loc %>% 
  select(parent.pop, elevation.group) %>% 
  unique() %>%
  bind_cols(os_weeks=0,
            prop.surviving=1 )

wl2_obs.pop <- 
  wl2_surv_dates_loc %>% select(parent.pop, death.date, os_weeks, status, elevation.group) %>%
  group_by(parent.pop) %>%
  mutate(total=n()) %>%
  group_by(parent.pop, os_weeks) %>%
  summarize(n.newly.dead=sum(status),
            total=unique(total),
            elevation.group=unique(elevation.group)) %>%
  ungroup() %>%
  complete(parent.pop, os_weeks, fill = list(n.newly.dead=0)) %>% # we have missing data for weeks where nobody died and we need to fill that in
  group_by(parent.pop) %>%
  mutate(total=unique(na.omit(total)), elevation.group=unique(na.omit(elevation.group)), # filling in the blanks from the complete() step above
         total.dead=cumsum(n.newly.dead),
         surviving = total - total.dead,
         prop.surviving = surviving/total) %>%
  ungroup() %>%
  bind_rows(week0.pop) %>%
  select(parent.pop, elevation.group, os_weeks, prop.surviving) %>%
  arrange(parent.pop, os_weeks)

wl2_obs.pop %>%
  ggplot(aes(x=os_weeks, y = prop.surviving, color = elevation.group)) +
  geom_smooth() +
  geom_point()

wl2_obs.pop %>%
  ggplot(aes(x=os_weeks, y = prop.surviving, color = parent.pop)) +
  geom_line() +
  geom_point()
```
### elevation-level summary

```{r}
week0.elev <- wl2_surv_dates_loc %>% 
  select(elevation.group) %>% 
  unique() %>%
  bind_cols(os_weeks=0,
            prop.surviving=1 )

wl2_obs.elev <-
  wl2_surv_dates_loc %>% select(death.date, os_weeks, status, elevation.group) %>%
  group_by(elevation.group) %>%
  mutate(total=n()) %>%
  group_by(elevation.group, os_weeks) %>%
  summarize(n.newly.dead=sum(status),
            total=unique(total)
            ) %>%
  ungroup() %>%
  complete(elevation.group, os_weeks, fill = list(n.newly.dead=0)) %>% # we have missing data for weeks where nobody died and we need to fill that in
  group_by(elevation.group) %>%
  mutate(total=unique(na.omit(total)), # filling in the blanks from the complete() step above
         total.dead=cumsum(n.newly.dead),
         surviving = total - total.dead,
         prop.surviving = surviving/total) %>%
  ungroup() %>%
  bind_rows(week0.elev) %>%
#  select(elevation.group, os_weeks, prop.surviving) %>%
  arrange(elevation.group, os_weeks)


wl2_obs_elev.summary <- wl2_obs.elev %>%
  group_by(os_weeks, elevation.group) %>%
  summarize(prop.surviving = mean(prop.surviving))


wl2_obs_elev.summary %>%
  ggplot(aes(x=os_weeks, y=prop.surviving, color=elevation.group )) +
  geom_point() +
  geom_line()

```


# Modeling probability of event rather than event time

An alternative approach to hazard analysis is to model the probably of death as a function of each time interval.

## Discrete intervals

Modify the input data to add some factor variables and to compute the total number of plants during each time period.
```{r}
wl2_obs.elev <- wl2_obs.elev %>% mutate(n=n.newly.dead + surviving,
                                        os_weeks_f = factor(str_pad(round(os_weeks, 1), 2, pad = "0")), # padding so it will sort correctly
                                        os_weeks_elev = str_c(elevation.group,"_", os_weeks_f)
)
wl2_obs.elev
```

### simple: time only

```{r}
m1 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_f, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m1)
```

The estimates above are on the logit scale.  Transform them back to hazard probabilities
```{r}
fixef(m1) %>% inv_logit_scaled()
```

```{r}
plot(m1, ask = FALSE, nvariables = 3)
```


### time and elevation


```{r}
m2 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_f + elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)

```


```{r}
summary(m2)
```

from logit to hazard probabilities:
```{r}
fixef(m2) %>% inv_logit_scaled()
```

```{r}
plot(m2, ask = FALSE, nvariables = 3)
```

### week and elevation interaction

```{r}
m3 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_f*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m3)
```

Transform logits to hazard probabilities
```{r}
fixef(m3) %>% inv_logit_scaled()
```

```{r}
plot(m3, ask = FALSE, nvariables = 3)
```

### another way to deal with this is just to set a discrete class for combo of week and elevation.group.  
this will make the output a bit easier to read and doesn't hamper the fit (see loo comparisons below)

```{r}
m4 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_elev, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m4)
```
logit to hazard probabilities
```{r}
fixef(m4) %>% inv_logit_scaled()
```

```{r}
plot(m4, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m1, m2, m3, m4)
```
m4 and m3 are equivalent.  m1 is notably worse and m2 is somewhat worse.

## plots from m4 and m2

“each time point's estimated survival probability is the successive product of the complement of the estimated hazard function probabilities across this and all previous timepoints” https://bookdown.org/content/4253/describing-discrete-time-event-occurrence-data.html#bonus-fit-the-discrete-time-hazard-models-with-brms

To make the plots, we start with posterior draws of the hazards conver to survival probabilities, and then take the cumulative product across the weeks (separately for each elevation group and draw).  Then we compute the median values and 95% credible intervals

### m4
```{r}
m4.plot.df <- as_draws_df(m4) %>%
  select(starts_with("b_")) %>%
  rename_with( ~ str_remove(.x, "b_os_weeks_elev")) %>%
  
  # transform hazards from logit to probability
  mutate(across(everything(), .fns = inv_logit_scaled)) %>%
  
  # convert hazard to survival probability (1 - hazard)
  mutate(across(everything(), .fns = ~ 1- .)) %>%
  
  # label the draws and pivot
  mutate(draw = 1:n()) %>%
  pivot_longer(-draw, names_to = c("elevation", "week"), names_sep = "_", values_to = "point.survivorship") %>%
  
  # calculate the cumulative survivorship
  arrange(elevation, draw, week) %>% 
  group_by(elevation, draw) %>%
  mutate(cum.survivorship = cumprod(point.survivorship)) %>%
  
  # calculate Bayesian highest density 95% credible intervals
  group_by(elevation, week) %>%
  point_interval(point.survivorship, cum.survivorship, .interval = hdci) %>%
  mutate(week = as.numeric(week))
```

```{r}
m4.plot.df %>%
  ggplot(aes(x = week, y = cum.survivorship, ymin = cum.survivorship.lower, ymax = cum.survivorship.upper, group = elevation)) +
  geom_ribbon(fill="grey50", alpha = .5) +
  geom_line(aes(color=elevation), lwd=1.5) +
  geom_point(aes(x=os_weeks, y = prop.surviving, color = elevation.group), data = wl2_obs_elev.summary, inherit.aes = FALSE) +
  scale_color_viridis_d() + 
  ggtitle("m4: n.dead ~ time*elevation")
```

### m2

```{r}
m2.plot.df <- 
as_draws_df(m2) %>%
  select(starts_with("b_")) %>%
  rename_with( ~ str_remove(.x, "b_")) %>%
  
# Add coefficients to get estimates for each elevation at each week.
  
  mutate(across(starts_with("os_weeks"), 
                .fns = list(Mid = ~ . + elevation.groupMid, High = ~ . + elevation.groupHigh)
  )) %>%
  rename_with( ~ str_c(., "_Low"), matches("[0-9]$")) %>% # the original week estimates are from the Low elevation
  select(-elevation.groupMid, - elevation.groupHigh) %>%
  
  
  # transform hazards from logit to probability
  mutate(across(everything(), .fns = inv_logit_scaled)) %>%
  
  # Convert hazard to probability of survivorship (1 - hazard)
  mutate(across(everything(), .fns = ~ 1- .)) %>%
  
  # label the draws and pivot
  mutate(draw = 1:n()) %>%
  pivot_longer(-draw, names_to = c("week", "elevation"), names_sep = "_", values_to = "point.survivorship", names_prefix = "os_weeks_f") %>%
  
  # calculate the cumulative survivorship
  arrange(elevation, draw, week) %>% 
  group_by(elevation, draw) %>%
  mutate(cum.survivorship = cumprod(point.survivorship)) %>%
  
  # calculalte Bayesian highest density 95% credible interval
  group_by(elevation, week) %>%
  point_interval(point.survivorship, cum.survivorship, .interval = hdci) %>%
  mutate(week = as.numeric(week))
```

```{r}
m2.plot.df %>%
  ggplot(aes(x = week, y = cum.survivorship, ymin = cum.survivorship.lower, ymax = cum.survivorship.upper, group = elevation)) +
  geom_ribbon(fill="grey50", alpha = .5) +
  geom_line(aes(color=elevation), lwd=1.5) +
  geom_point(aes(x=os_weeks, y = prop.surviving, color = elevation.group), data = wl2_obs_elev.summary, inherit.aes = FALSE) +
  scale_color_viridis_d() +
  ggtitle("m2: n.dead ~ time + elevation")
```

TODO:

[] Random effects
[] Time as (polynomial) continuous
[] Time as a smoothed continuous
[] BRMS time-to-event parameterization (maybe)
[] Environmental co-variates


## Continuous time

### linear

```{r}
m5 <- brm(n.newly.dead | trials(n)  ~ os_weeks*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```
```{r}
summary(m5)
```


logit to hazard probabilities
```{r}
fixef(m5) %>% inv_logit_scaled()
```

```{r}
plot(m5, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m1, m2, m3, m4, m5)
```
OK that does not fit well at all.

What about quadratic?

### Quadratic

```{r}
m6 <- brm(n.newly.dead | trials(n)  ~ os_weeks*elevation.group + I(os_weeks^2)*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          iter = 3000,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
summary(m6)
```


logit to hazard probabilities
```{r}
fixef(m6) %>% inv_logit_scaled()
```
Wide confidence intervals on some of those coefficients...

```{r}
plot(m6, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m1, m2, m3, m4, m5, m6)
```
It does do a decent job, although marginally not as good as the best.

The confidence intervals on the coefficients for the elevation:linear time term include 0.  how about a model without those interactions?


```{r}
m7 <- brm(n.newly.dead | trials(n)  ~  os_weeks + elevation.group + I(os_weeks^2)*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
summary(m7)
```

no parameter estimates crossing zero, this is nicer than m6

logit to hazard probabilities
```{r}
fixef(m7) %>% inv_logit_scaled()
```

```{r}
plot(m7, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m6,m7)
loo_compare(m1, m2, m3, m4, m5, m6, m7)
```
Although about the same as m6 on the loo scale.  Still, we would go with the simpler model (m7)

### Extracting and plotting from m7

This is somewhat differnet than m1 - m4 because now we have a function of time.

Tidybayes can help.  See https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-brms.html

One thing I can't figure out is how to do cumulative survivorship if we use something other than the original intervals.  But I haven't looked at the book yet.

```{r}
wl2_obs.elev %>% 
  na.omit() %>% #get rid of week 0
  data_grid(os_weeks, elevation.group, n=1) %>%
  
  # Add the discrete hazard probabilities
  add_epred_draws(m7) %>% 

  # convert hazard to survival probability (1 - hazard)
  mutate(point.survivorship = 1 - .epred) %>%
  
  # calculate the cumulative survivorship
  arrange(elevation.group, .draw, os_weeks) %>% 
  group_by(elevation.group, .draw) %>%
  mutate(cum.survivorship = cumprod(point.survivorship)) %>%
  
  # calculate Bayesian highest density 95% credible intervals
  group_by(elevation.group, os_weeks) %>%
  point_interval(point.survivorship, cum.survivorship, .interval = hdci) %>%
  
    ggplot(aes(x = os_weeks, y = cum.survivorship, ymin = cum.survivorship.lower, ymax = cum.survivorship.upper, group = elevation.group)) +
  geom_ribbon(fill="grey50", alpha = .5) +
  geom_line(aes(color=elevation.group), lwd=1.5) +
  geom_point(aes(x=os_weeks, y = prop.surviving, color = elevation.group), data = wl2_obs_elev.summary, inherit.aes = FALSE) +
  scale_color_viridis_d() + 
  ggtitle("m7: n.newly.dead | trials(n) ~ os_weeks + elevation.group + I(os_weeks^2) * elevation.group ")
```

### Cubic

I am not including a cubic interaction term.  The estimates of that were very small and the confidence intervals included zero (not shown)

```{r}
m8 <- brm(n.newly.dead | trials(n)  ~  os_weeks + elevation.group + I(os_weeks^2)*elevation.group + I(os_weeks^3), 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE),
          control = list( max_treedepth = 20)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
summary(m8)
```

no parameter estimates crossing zero, this is nicer than m6

logit to hazard probabilities
```{r}
fixef(m8) %>% inv_logit_scaled()
```

```{r}
plot(m8, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m7,m8)
loo_compare(m1, m2, m3, m4, m5, m6, m7, m8)
```
Although about the same as m7 on the loo scale, so we would favor the simpler model (m7) based on this.  Go ahead and plot it.

### Extracting and plotting from m8

```{r}
wl2_obs.elev %>% 
  na.omit() %>% #get rid of week 0
  data_grid(os_weeks, elevation.group, n=1) %>%
  
  # Add the discrete hazard probabilities
  add_epred_draws(m8) %>% 

  # convert hazard to survival probability (1 - hazard)
  mutate(point.survivorship = 1 - .epred) %>%
  
  # calculate the cumulative survivorship
  arrange(elevation.group, .draw, os_weeks) %>% 
  group_by(elevation.group, .draw) %>%
  mutate(cum.survivorship = cumprod(point.survivorship)) %>%
  
  # calculate Bayesian highest density 95% credible intervals
  group_by(elevation.group, os_weeks) %>%
  point_interval(point.survivorship, cum.survivorship, .interval = hdci) %>%
  
    ggplot(aes(x = os_weeks, y = cum.survivorship, ymin = cum.survivorship.lower, ymax = cum.survivorship.upper, group = elevation.group)) +
  geom_ribbon(fill="grey50", alpha = .5) +
  geom_line(aes(color=elevation.group), lwd=1.5) +
  geom_point(aes(x=os_weeks, y = prop.surviving, color = elevation.group), data = wl2_obs_elev.summary, inherit.aes = FALSE) +
  scale_color_viridis_d() + 
  ggtitle("m8: n.newly.dead | trials(n) ~ os_weeks + elevation.group + I(os_weeks^2) * elevation.group + I(os_weeks^3) ")
```
