---
title: "WL2_Survival-Analysis"
author: "Julin Maloof"
date: '`r Sys.Date()`'
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Survival Analysis 

See chapters 9 - 13 in tutorial: https://bookdown.org/content/4253/extending-the-discrete-time-hazard-model.html

## Libraries
```{r}
# install.packages(c("ggsurvfit", "gtsummary"))
library(tidyverse) #includes lubridate, which we need 
library(ggrepel)
#library(ggsurvfit)
#library(gtsummary)
library(brms)
library(ggdist)
library(tidybayes)
library(modelr)
#library(bayesplot)
options(mc.cores = parallel::detectCores())
```

## Read in the data
```{r}
wl2_surv <- read_csv("../output/WL2_Traits/WL2_Mortality_2023.csv")
```

As weeks
```{r}
wl2_surv %>% filter(is.na(death.date),!is.na(survey.notes)) #no plants that seemed to disappear 
wl2_surv %>% filter(Genotype=="YO7_4_2")

wl2_surv_dates <- wl2_surv %>%  
  rename(parent.pop = pop) %>%
  mutate(parent.pop= str_replace(parent.pop, "Y08", "YO8")) %>% 
  mutate(parent.pop= str_replace(parent.pop, "Y04", "YO4")) %>% 
  filter(!is.na(parent.pop)) %>% 
  mutate(planting.date="7/19/23", #could try to make this more specific to when certain blocks were planted 
         last_fup_date=if_else(is.na(death.date), "10/27/23", death.date)) %>%  #need this to calculate survival times
  mutate(planting.date=mdy(planting.date), last_fup_date=mdy(last_fup_date)) %>% #convert to date objects
  mutate(os_weeks=as.duration(planting.date %--% last_fup_date) / dweeks(1), #observed number of weeks
         status=if_else(is.na(death.date), 0, 1)) %>% #0=censured (alive in this case), 1=dead
  filter(os_weeks > 0) %>% #there is one case of a plant that was dead at planting, so just removed it since this is survival post- transplanting
  select(-survey.notes)
head(wl2_surv_dates)
unique(wl2_surv_dates$os_weeks) %>% sort()
```


## Location Info

using full year for now
```{r}
gowersdist_WL2 <- read_csv("../output/Climate/Gowers_WL2.csv") 
head(gowersdist_WL2)
```

```{r}
wl2_surv_dates_loc <- left_join(wl2_surv_dates, gowersdist_WL2 %>% filter(TimePd == "Historical")) %>%
  mutate(elevation.group = factor(elevation.group, levels= c("Low", "Mid", "High")))
wl2_surv_dates_loc
```


## plot observed data

Need to summarize separately for pops and for elevation.  It is a mistake to average pops and then elevation, at least with respect to comparing to population naive models

### population-level summary
```{r}
wl2_obs.pop <- 
  wl2_surv_dates_loc %>% select(parent.pop, death.date, os_weeks, status, elevation.group) %>%
  group_by(parent.pop) %>%
  mutate(total=n()) %>%
  group_by(parent.pop, os_weeks) %>%
  summarize(n.newly.dead=sum(status),
            total=unique(total),
            elevation.group=unique(elevation.group)) %>%
  ungroup() %>%
  complete(parent.pop, os_weeks, fill = list(n.newly.dead=0)) %>% # we have missing data for weeks where nobody died and we need to fill that in
  group_by(parent.pop) %>%
  mutate(total=unique(na.omit(total)), elevation.group=unique(na.omit(elevation.group)), # filling in the blanks from the complete() step above
         total.dead=cumsum(n.newly.dead),
         surviving = total - total.dead,
         prop.surviving = surviving/total) %>%
  ungroup() %>%
#  bind_rows(week0.pop) %>%
#  select(parent.pop, elevation.group, os_weeks, prop.surviving) %>%
  arrange(parent.pop, os_weeks)

# Add a week 0 with all plants

wl2_obs.pop.0 <- wl2_obs.pop %>%
  filter(os_weeks==1) %>%
   mutate(os_weeks = 0,
          n.newly.dead = 0,
          total.dead = 0,
          surviving = total,
          prop.surviving = 1) %>%
   rbind(wl2_obs.pop) %>%
   arrange(parent.pop, os_weeks)

wl2_obs.pop.0 %>%
  ggplot(aes(x=os_weeks, y = prop.surviving, color = elevation.group)) +
  geom_smooth() +
  geom_point()

wl2_obs.pop.0 %>%
  ggplot(aes(x=os_weeks, y = prop.surviving, color = parent.pop)) +
  geom_line() +
  geom_point()
```

## Some additional summaries

```{r}
# total number of plants:
wl2_obs.pop.0 %>%
  filter(os_weeks==0) %>%
  select(parent.pop, total) %>%
  pull(total) %>% sum()
```

## select 50% of dead plants to omit per week1 and week2

```{r}
wl2_obs.pop.0 %>%
  filter(os_weeks > 0) %>%
  mutate(dead_50 = floor(n.newly.dead/2)) %>%
  group_by(os_weeks) %>%
  summarize(omit = sum(dead_50)) 
  
```

How many plants are alive at the end?

```{r}
wl2_obs.pop.0 %>%
  filter(os_weeks > 13) 

wl2_obs.pop.0 %>%
  filter(os_weeks > 13) %>%
  pull(surviving) %>%
  sum()

wl2_obs.pop.0 %>%
  filter(os_weeks > 13) %>%
  pull(total.dead) %>%
  sum()
```


### elevation-level summary

```{r}
wl2_obs.elev <-
  wl2_surv_dates_loc %>% select(death.date, os_weeks, status, elevation.group) %>%
  group_by(elevation.group) %>%
  mutate(total=n()) %>%
  group_by(elevation.group, os_weeks) %>%
  summarize(n.newly.dead=sum(status),
            total=unique(total)
            ) %>%
  ungroup() %>%
  complete(elevation.group, os_weeks, fill = list(n.newly.dead=0)) %>% # we have missing data for weeks where nobody died and we need to fill that in
  group_by(elevation.group) %>%
  mutate(total=unique(na.omit(total)), # filling in the blanks from the complete() step above
         total.dead=cumsum(n.newly.dead),
         surviving = total - total.dead,
         prop.surviving = surviving/total) %>%
  ungroup()  %>%
   arrange(elevation.group, os_weeks)

# Add a week 0 with all plants

wl2_obs.elev.0 <- wl2_obs.elev %>%
  filter(os_weeks==1) %>%
   mutate(os_weeks = 0,
          n.newly.dead = 0,
          total.dead = 0,
          surviving = total,
          prop.surviving = 1) %>%
   rbind(wl2_obs.elev) %>%
   arrange(elevation.group, os_weeks)

wl2_obs_elev.summary <- wl2_obs.elev.0 %>%
  group_by(os_weeks, elevation.group) %>%
  summarize(prop.surviving = mean(prop.surviving))

wl2_obs_elev.summary %>%
  ggplot(aes(x=os_weeks, y=prop.surviving, color=elevation.group )) +
  geom_point() +
  geom_line()

```


# Modeling probability of event rather than event time

An alternative approach to hazard analysis is to model the probably of death as a function of each time interval.

## Discrete intervals

Modify the input data to add some factor variables and to compute the total number of plants during each time period.
```{r}
wl2_obs.elev <- wl2_obs.elev %>% mutate(n=n.newly.dead + surviving,
                                        os_weeks_f = factor(str_pad(round(os_weeks, 1), 2, pad = "0")), # padding so it will sort correctly
                                        os_weeks_elev = factor(str_c(elevation.group,"_", os_weeks_f))
)
wl2_obs.elev

wl2_obs.elev.0 <- wl2_obs.elev.0 %>% mutate(n=n.newly.dead + surviving,
                                        os_weeks_f = factor(str_pad(round(os_weeks, 1), 2, pad = "0")), # padding so it will sort correctly
                                        os_weeks_elev = factor(str_c(elevation.group,"_", os_weeks_f))
)

wl2_obs.elev.0
```
Create a plotting function for plotting the fits below:

```{r}
plot_fit_elev <- function(m, mname=NA, d=wl2_obs.elev.0, dsum=wl2_obs_elev.summary, include.week0=FALSE) {
  if(is.na(mname)) mname <- deparse(substitute(m)) 
  title = str_c(mname, ": ", {formula(m) %>% as.character %>% magrittr::extract2(1)})
  
  if(!include.week0) d <- d %>% filter(os_weeks > 0)
  
  d %>% 
    data_grid(os_weeks, elevation.group, n=1) %>%
    mutate(os_weeks_f = factor(str_pad(round(os_weeks, 1), 2, pad = "0")), # padding so it will sort correctly
           os_weeks_elev = factor(str_c(elevation.group,"_", os_weeks_f))) %>%
    
    # Add the discrete hazard probabilities
    add_epred_draws(m) %>% 
    
    # convert hazard to survival probability (1 - hazard)
    mutate(point.survivorship = 1 - .epred) %>%
    
    # calculate the cumulative survivorship
    arrange(elevation.group, .draw, os_weeks) %>% 
    group_by(elevation.group, .draw) %>%
    mutate(cum.survivorship = cumprod(point.survivorship)) %>%
    
    # calculate Bayesian highest density 95% credible intervals
    group_by(elevation.group, os_weeks) %>%
    point_interval(point.survivorship, cum.survivorship, .interval = hdci) %>%
    
    ggplot(aes(x = os_weeks, y = cum.survivorship, ymin = cum.survivorship.lower, ymax = cum.survivorship.upper, group = elevation.group)) +
    geom_ribbon(fill="grey50", alpha = .5) +
    geom_line(aes(color=elevation.group), lwd=1.5) +
    geom_point(aes(x=os_weeks, y = prop.surviving, color = elevation.group), data = dsum, inherit.aes = FALSE) +
    scale_color_viridis_d() + 
    ggtitle(title) +
    theme(plot.title = element_text(size = 10))
}
```

### simple: time only

no week 0 data
```{r}
m1 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_f, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```

with week 0
```{r}
m1.w0 <- update(m1, newdata = wl2_obs.elev.0)  %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m1)
```

The estimates above are on the logit scale.  Transform them back to hazard probabilities
```{r}
fixef(m1) %>% inv_logit_scaled()
```

```{r}
plot(m1, ask = FALSE, nvariables = 3)
```


### time and elevation


```{r}
m2 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_f + elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)

```


```{r}
m2.w0 <- update(m2, newdata = wl2_obs.elev.0)  %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m2)
```

```{r}
summary(m2.w0)
```

from logit to hazard probabilities:
```{r}
fixef(m2) %>% inv_logit_scaled()
fixef(m2.w0) %>% inv_logit_scaled()

```

```{r}
plot(m2, ask = FALSE, nvariables = 3)
```

### week and elevation interaction

```{r}
m3 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_f*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE, reloo = TRUE)
```

```{r}
m3.w0 <- update(m3, newdata = wl2_obs.elev.0)  %>%
  add_criterion("loo", moment_match = TRUE, reloo = TRUE)
```

```{r}
summary(m3)
summary(m3.w0)
```

Transform logits to hazard probabilities
```{r}
fixef(m3) %>% inv_logit_scaled()
```

```{r}
plot(m3, ask = FALSE, nvariables = 3)
```

### another way to deal with this is just to set a discrete class for combo of week and elevation.group.  
this will make the output a bit easier to read and doesn't hamper the fit (see loo comparisons below)

```{r}
m4 <- brm(n.newly.dead | trials(n)  ~ 0 + os_weeks_elev, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE) # reloo gives an error so not using it
```

```{r}
# update model not working here because of factor levels

m4.w0 <- update(m4, newdata = wl2_obs.elev.0) %>%
  add_criterion("loo", moment_match = TRUE) #, reloo = TRUE) gives an error, not using it


```


Levels allowed: 'High_00', 'High_01', 'High_02', 'High_03', 'High_04', 'High_05', 'High_06', 'High_07', 'High_08', 'High_09', 'High_10', 'High_12.3', 'High_13.3', 'Low_00', 'Low_01', 'Low_02', 'Low_03', 'Low_04', 'Low_06', 'Low_07', 'Low_08', 'Low_09', 'Low_10', 'Low_12.3', 'Low_13.3', 'Mid_00', 'Mid_01', 'Mid_02', 'Mid_03', 'Mid_04', 'Mid_05', 'Mid_06', 'Mid_07', 'Mid_08', 'Mid_09', 'Mid_10', 'Mid_12.3', 'Mid_13.3'


```{r}
summary(m4)
summary(m4.w0)
```
logit to hazard probabilities
```{r}
fixef(m4) %>% inv_logit_scaled()
```

```{r}
plot(m4, ask = FALSE, nvariables = 3)
```

Compare models without week 0
```{r}
loo_compare(m1, m2, m3, m4)
```
m4 and m3 are equivalent.  m1 is notably worse and m2 is somewhat worse.

Compare models with week 0
```{r}
loo_compare(m1.w0, m2.w0, m3.w0, m4.w0)
```
m4 is maybe slightly worse

## plots from m4 and m2

“each time point's estimated survival probability is the successive product of the complement of the estimated hazard function probabilities across this and all previous timepoints” https://bookdown.org/content/4253/describing-discrete-time-event-occurrence-data.html#bonus-fit-the-discrete-time-hazard-models-with-brms

To make the plots, we start with posterior draws of the hazards, convert to survival probabilities, and then take the cumulative product across the weeks (separately for each elevation group and draw).  Then we compute the median values and 95% credible intervals

### m4
```{r}
plot_fit_elev(m4)
```

### m4 week 0

```{r}
plot_fit_elev(m4.w0, include.week0 = TRUE)
```

### m2

```{r}
plot_fit_elev(m2)
```


### m2 with week 0

```{r}
plot_fit_elev(m2.w0, include.week0 = TRUE)
```


TODO:

[] Random effects
[*] Time as (polynomial) continuous
[*] Time as a smoothed continuous
[] BRMS time-to-event parameterization (maybe)
[] Environmental co-variates


## Continuous time

### linear

```{r}
  m5 <- brm(n.newly.dead | trials(n)  ~ os_weeks*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
m5.w0 <- update(m5, newdata = wl2_obs.elev.0) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
summary(m5)
summary(m5.w0)
```


logit to hazard probabilities
```{r}
fixef(m5) %>% inv_logit_scaled()
```

```{r}
plot(m5, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m1, m2, m3, m4, m5)
```
```{r}
loo_compare(m1.w0, m2.w0, m3.w0, m4.w0, m5.w0)
```

OK that does not fit well at all.

What about quadratic?

### Quadratic

```{r}
m6 <- brm(n.newly.dead | trials(n)  ~ os_weeks*elevation.group + I(os_weeks^2)*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          iter = 3000,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
m6.w0 <- update(m6, newdata = wl2_obs.elev.0) %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m6)
summary(m6.w0)
```


logit to hazard probabilities
```{r}
fixef(m6) %>% inv_logit_scaled()
```

```{r}
plot(m6, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m1, m2, m3, m4, m5, m6)
```

```{r}
loo_compare(m1.w0, m2.w0, m3.w0, m4.w0, m5.w0, m6.w0)
```


For the model without week 0, it does an okay job, but the confidence intervals on the coefficients for the elevation:linear time term include 0.  how about a model without those interactions?

For the model with week 0, the confidence intervals do not cross 0.  it also does a terrible job.  Won't pursue m7 for week0 data


```{r}
m7 <- brm(n.newly.dead | trials(n)  ~  os_weeks + elevation.group + I(os_weeks^2)*elevation.group, 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
m7.w0 <- update(m7, newdata = wl2_obs.elev.0) %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m7)
```

logit to hazard probabilities
```{r}
fixef(m7) %>% inv_logit_scaled()
```

```{r}
plot(m7, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m6,m7)
loo_compare(m1, m2, m3, m4, m5, m6, m7)
```
About the same as m6 on the loo scale.  Would go with the simpler model (m7)

```{r}
loo_compare(m1.w0, m2.w0, m3.w0, m4.w0, m5.w0, m6.w0, m7.w0)
```


### plotting

One thing I can't figure out is how to do cumulative survivorship if we use something other than the original intervals.  But I haven't looked at the book yet.

```{r}
plot_fit_elev(m7)
```

### Cubic

I am not including a cubic interaction term.  The estimates of that were very small and the confidence intervals included zero (not shown)

```{r}
m8 <- brm(n.newly.dead | trials(n)  ~  os_weeks + elevation.group + I(os_weeks^2)*elevation.group + I(os_weeks^3), 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE),
          control = list( max_treedepth = 20)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
m8.w0 <- update(m8, newdata = wl2_obs.elev.0) %>%
  add_criterion("loo", moment_match = TRUE)
```


```{r}
summary(m8)
summary(m8.w0)
```

no parameter estimates crossing zero, this is nicer than m6

logit to hazard probabilities
```{r}
fixef(m8) %>% inv_logit_scaled()
```

```{r}
plot(m8, ask = FALSE, nvariables = 3)
```
```{r}
plot(m8.w0, ask = FALSE, nvariables = 3)
```

```{r}
prior_summary(m8.w0)
```
Try a different intercept prior

```{r}
m8.w0.1 <- brm(n.newly.dead | trials(n)  ~ 0 + Intercept + os_weeks + elevation.group + I(os_weeks^2)*elevation.group + I(os_weeks^3), 
          prior(normal(0, 4), class = b) + prior(normal(-10, 2), class = b, coef = Intercept),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev.0),
          save_pars = save_pars(all = TRUE),
          control = list( max_treedepth = 20)) %>%
  add_criterion("loo", moment_match = TRUE)
```

```{r}
summary(m8.w0.1)
```


```{r}
loo_compare(m7,m8)
loo_compare(m1, m2, m3, m4, m5, m6, m7, m8)
```
Although about the same as m7 on the loo scale, so we would favor the simpler model (m7) based on this.  Go ahead and plot it.

```{r}
loo_compare(m1.w0, m2.w0, m3.w0, m4.w0, m5.w0, m6.w0, m7.w0, m8.w0, m8.w0.1)
```


### Extracting and plotting from m8

```{r}
plot_fit_elev(m8)
```

```{r}
plot_fit_elev(m8.w0, include.week0 = TRUE)
```

### Smoothed, no interaction, default

using default parameters for `s()`.  Could modify number of knots, etc.  See `mgcv::s`
```{r}
m9 <- brm(n.newly.dead | trials(n)  ~  elevation.group + s(os_weeks) , 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
m9.w0 <- update(m9, newdata = wl2_obs.elev.0) %>%
    add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```


```{r}
summary(m9)
summary(m9.w0)
```

logit to hazard probabilities
```{r}
fixef(m9) %>% inv_logit_scaled()
```

```{r}
plot(m9, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m1, m2, m3, m4, m5, m6, m7, m8, m9)
```


```{r}
loo_compare(m1.w0, m2.w0, m3.w0, m4.w0, m5.w0, m6.w0, m7.w0, m8.w0, m9.w0)
```

not the best but better than any of the linear / polynomial models

### Extracting and plotting from m9

```{r}
plot_fit_elev(m9)
```

```{r}
plot_fit_elev(m9.w0, include.week0 = TRUE)
```

### smoothed, with interaction, default

using default parameters for `s()`.  Could modify number of knots, etc.  See `mgcv::s`
```{r}
m10 <- brm(n.newly.dead | trials(n)  ~  elevation.group + s(os_weeks, by=elevation.group) , 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
#m10.w0 <- update(m10, newdata = wl2_obs.elev.0) %>%
#  add_criterion("loo", moment_match = TRUE, reloo = TRUE)

# starting without update, just in case

m10.w0 <- brm(n.newly.dead | trials(n)  ~  elevation.group + s(os_weeks, by=elevation.group) , 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev.0),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```


```{r}
summary(m10)
summary(m10.w0)
```

```{r}
plot(m10, ask = FALSE, nvariables = 3)
```

```{r}
loo_compare(m1, m2, m3, m4, m5, m6, m7, m8, m9, m10)
```

```{r}
loo_compare(m1.w0, m2.w0, m3.w0, m4.w0, m5.w0, m6.w0, m7.w0, m8.w0, m9.w0, m10.w0)
```

huh, without week 0 data it is as good as the best, but with week 0 it is the worst! (But see below...the fit looks great...)

what about WAIC? WAIC gives a warning. What about bayes R2?

```{r}
bayes_R2(m4.w0)
bayes_R2(m9.w0)
bayes_R2(m10.w0)
```
Tighter priors on the smoothing coefficients:

```{r}
m10.w0.1 <- brm(n.newly.dead | trials(n)  ~  elevation.group + s(os_weeks, by=elevation.group) , 
          prior(normal(0, 4), class = b) + prior(normal(0,1), class = sds), #tigher priors on "wigglieness" of smoothing splines
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev.0),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
plot(m10.w0.1, ask = FALSE)
```


```{r}
loo_compare(m4.w0, m9.w0, m10.w0, m10.w0.1)
```
what about penalizing the splines?


```{r}
m10.w0.2 <- brm(n.newly.dead | trials(n)  ~  elevation.group + s(os_weeks, by=elevation.group, bs = "ts") , 
          prior(normal(0, 4), class = b) + prior(normal(0,1), class = sds), #tigher priors on "wigglieness" of smoothing splines
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev.0),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
plot(m10.w0.2, ask = FALSE)
```

```{r}
m10.w0.3 <- brm(n.newly.dead | trials(n)  ~  elevation.group + s(os_weeks, by=elevation.group, bs = "ps") , 
          prior(normal(0, 4), class = b) + prior(normal(0,1), class = sds), #tigher priors on "wigglieness" of smoothing splines
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev.0),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
m10.w0.4 <- brm(n.newly.dead | trials(n)  ~  elevation.group + s(os_weeks, by=elevation.group, bs = "cc") , 
          prior(normal(0, 4), class = b) + prior(normal(0,1), class = sds), #tigher priors on "wigglieness" of smoothing splines
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev.0),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
plot(m10.w0.2, ask = FALSE)
```

```{r}
loo_compare(m4.w0, m9.w0, m10.w0, m10.w0.1, m10.w0.2, m10.w0.3, m10.w0.4)
```

### Extracting and plotting from m10

```{r}
plot_fit_elev(m10)
```



```{r}
plot_fit_elev(m10.w0, include.week0 = TRUE)
```

```{r}
#m10.w0 <- update(m10, newdata = wl2_obs.elev.0) %>%
#  add_criterion("loo", moment_match = TRUE, reloo = TRUE)

# starting without update, just in case

m11.w0 <- brm(n.newly.dead | trials(n)  ~  s(os_weeks, by=elevation.group) , 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = na.omit(wl2_obs.elev.0),
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
loo_compare(m4.w0, m10.w0, m11.w0)
```


```{r}
#m10.w0 <- update(m10, newdata = wl2_obs.elev.0) %>%
#  add_criterion("loo", moment_match = TRUE, reloo = TRUE)

# starting without update, just in case

m12.w0 <- brm(n.newly.dead | trials(n)  ~  s(os_weeks, by=elevation.group) , 
          prior(normal(0, 4), class = b),
          family = "binomial",
          chains = 4, cores = 4, refresh = 0,
          data = {na.omit(wl2_obs.elev.0) %>% mutate(os_weeks = scale(os_weeks, scale=FALSE)) },
          save_pars = save_pars(all = TRUE),
          control = list(adapt_delta = 0.99, max_treedepth = 20, stepsize=0.1)) %>%
  add_criterion("loo", moment_match = TRUE, reloo=TRUE)
```

```{r}
loo_compare(m3.w0, m4.w0, m9.w0, m10.w0, m11.w0, m12.w0)
```


```{r}
save.image(file = "../output/WL2_Surv_BRMS_Fits.Rdata")
```

# Summary

```{r}
load(file = "../output/WL2_Surv_BRMS_Fits.Rdata")
```


## With week 0

Let's get the formula used
```{r}
w0.tmpname <- ls(pattern="m.*w0(|\\.[1-9])+$") 
  
w0.models <- tibble(mname=w0.tmpname) %>%
    mutate(model=map(mname, get),
           formula=map_chr(model, \(x) formula(x) %>% as.character %>% magrittr::extract2(1))) %>%
  arrange( order=as.numeric(str_extract(mname, "[0-9]+"))) %>%
  select(mname, formula, model)
```

```{r}
w0.models <- w0.models %>%
  mutate(loo = map(model, loo)) %>%
  pull(loo, name = mname) %>% 
  loo_compare() %>%
  as_tibble(rownames = "mname") %>%
  select(mname, elpd_diff, se_diff) %>%
  full_join(w0.models)

w0.models
```

The best fit is `m3.w0`, closely followed by `m4.w0`.  These are binomial models with separate fits for each week and elevation group.  The parameterization in m4.w0 makes the summary a bit easier to digest.

For the models with continuous time, best is `m9.w0` an additive model with time and elevation.  More complex models with continuous time actually fit the data better (by eye) but are being penalized because of the large number of parameters.


plots, ordered by elpd_loo
```{r, fig.width=8}
w0.models <- w0.models %>% mutate(plot=map2(model, mname, plot_fit_elev, include.week0 = TRUE))
w0.models$plot
```

plots, orderd by name
```{r, fig.width=8}
w0.models %>% 
  arrange( order=as.numeric(str_extract(mname, "[0-9]+"))) %>%
  pull(plot)
```


## without w0

Let's get the formula used
```{r}
w1.tmpname <- ls(pattern="m[0-9]+$") 
  
w1.models <- tibble(mname=w1.tmpname) %>%
    mutate(model=map(mname, get),
           formula=map_chr(model, \(x) formula(x) %>% as.character %>% magrittr::extract2(1))) %>%
  arrange( order=as.numeric(str_extract(mname, "[0-9]+"))) %>%
  select(mname, formula, model)
```

```{r}
w1.models %>%
  mutate(loo = map(model, loo)) %>%
  pull(loo, name = mname) %>% 
  loo_compare() %>%
  as_tibble(rownames = "mname") %>%
  select(mname, elpd_diff, se_diff) %>%
  full_join(w1.models)
```

plots, ordered by elpd_loo
```{r, fig.width=8}
w1.models <- w1.models %>% mutate(plot=map2(model, mname, plot_fit_elev, include.week0 = FALSE))
w1.models$plot
```

plots, orderd by name
```{r, fig.width=8}
w1.models %>% 
  arrange( order=as.numeric(str_extract(mname, "[0-9]+"))) %>%
  pull(plot)
```